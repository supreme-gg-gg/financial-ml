# -*- coding: utf-8 -*-
"""Jefferson DNN Regressor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fn-pI9QbmVGZGMXmYzAvikLNRWhgQrfA
"""

import torch
import torch.nn as nn
import yfinance as yf
import matplotlib.pyplot as plt

device = "cuda" if torch.cuda.is_available() else "cpu"

ticker = "^RUT"
data = yf.download(ticker, start="2012-01-01", end="2024-08-15", interval="1d")
selected_columns = data[['Open', 'High', 'Low', 'Close']]

def walk_forward_split(start_year, train_years, test_years):
  train_mask = (selected_columns.index[:] >= f'{start_year}-01-01') & (selected_columns.index[:] < f'{start_year + train_years}-01-01')
  test_mask = (selected_columns.index[:] >= f'{start_year + train_years}-01-01') & (selected_columns.index[:] < f'{start_year + train_years + test_years}-01-01')

  train_split = torch.tensor(selected_columns[train_mask].values, dtype=torch.float32).to(device)
  test_split = torch.tensor(selected_columns[test_mask].values, dtype=torch.float32).to(device)

  x_train = []
  y_train = []
  x_test = []
  y_test = []

  # Create batches
  for i in range(train_split.shape[0] - 10):
    x_train.append(train_split[i:i+10].flatten())
    y_train.append(train_split[i+10, 3])

  for i in range(test_split.shape[0] - 10):
    x_test.append(test_split[i:i+10].flatten())
    y_test.append(test_split[i+10, 3])

  x_train = torch.stack(x_train, dim = 0).to(device)
  y_train = torch.tensor(y_train, dtype=torch.float32).to(device)
  x_test = torch.stack(x_test, dim = 0).to(device)
  y_test = torch.tensor(y_test, dtype=torch.float32).to(device)

  return x_train, y_train, x_test, y_test

model_0 = StockRegressorModel().to(device)

class StockRegressorModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.linear1 = nn.Linear(40, 10)
    self.linear2 = nn.Linear(10, 10)
    self.linear3 = nn.Linear(10, 10)
    self.linear4 = nn.Linear(10, 1)
    self.relu = nn.ReLU()
  def forward(self, x):
      out = self.linear1(x)
      out = self.relu(out)

      out = self.linear2(out)
      out = self.relu(out)

      out = self.linear3(out)
      out = self.relu(out)

      out = self.linear4(out)
      return out.squeeze()  # Squeeze to remove potential singleton dimension

EPOCHS = 10000
LEARNING_RATE = 0.001
loss_fn = nn.MSELoss()
optimizer = torch.optim.SGD(params=model_0.parameters(), lr=LEARNING_RATE)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer= optimizer, step_size=1000, gamma=0.1)
RUNS = 1
STARTING_YEAR = 2012
TRAIN_YEARS = 3
TEST_YEARS = 1

for run in range(RUNS):
  x_train, y_train, x_test, y_test = walk_forward_split(STARTING_YEAR + run, TRAIN_YEARS, TEST_YEARS)

  # Training loop
  for epoch in range(EPOCHS):
    model_0.train()
    y_pred = model_0(x_train)
    loss = loss_fn(y_pred, y_train)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    scheduler.step()
    print(loss)

  # Test
  # model_0.eval()
  # with torch.inference_mode():
  #   y_pred = model_0(x_train)
  #   test_loss = loss_fn(y_pred, y_train)
  #

  plt.figure(figsize=(10, 6))
  plt.plot(y_train.cpu().detach().numpy(), label="Actual")
  plt.plot(y_pred.cpu().detach().numpy(), label="Predicted")
  plt.title("Stock Price Prediction vs Actual")
  plt.xlabel("Time Steps")
  plt.ylabel("Stock Price")
  plt.legend()
  plt.show()